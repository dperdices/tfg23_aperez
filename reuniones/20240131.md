# ¿Qué hemos hecho?
- Leer papers
- Descargar dataset


# Tareas
- Preprocesado: cargar datos (pcaps), pasarlo a secuencias de numeros
    - Hay que saltarse cabeceras (a partir de nivel de aplicación).
    - Guardar el resultado en un formato aceptable.
    - Incluir longitud del paquete en el dataset. Padding a cero (rellenar hasta la longitud deseada)
    - Incluir etiquetas

- Tokenizacion: Convertir bytes de paquete a tokens (numeros enteros)
    - Partir el paquete en palabras/tokens. Longitud?
        - **1B: 0-255, no hay que hacer nada**
        - 2B: 0-65535, todavía estamos bien.
        - 4B u 8B: no.

- Modelo:
    - TF-IDF (libreria sklearn o desarrollarlo a mano)
    - Word2vec (libreria gensim)
    - Redes neuronales
        - CNN
        - RNN (LSTM)
        - Transformer

- Programacion del modelo:
    - Frameworks: 
        - keras: el más alto nivel, pero el más estricto/cerrado.
        - pytorch: el más cacharreable, más usado a nivel de investigación, pero difícil.
        - jax: parecido a pytorch.

- Entrenarlo

- Evaluarlo:
    - Métricas
    - Comparación
        - Variar parámetros
